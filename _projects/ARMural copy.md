---
title: "AR Mural"
description: "My setup was all software-based for this experiment. Since I didn't have access to an actual PUF and didn't have the actual timing delays like the paper, I found a Python library to simulate a PUF. The pypuf library provides a toolbox for simulating a variety of PUFs, generating CRPs for training, and even testing PUFs on user-created challenges. Regarding the actual machine learning of the attack, I used PyTorch since I have used it for previous machine learning projects. For the basic pipeline, I split the attacks with three different scripts. In each script, I construct the model, and then to determine which PUF I use to run the attack on, I have a parameter the user can choose before they run the script. Once set, the script first creates the PUF with the library with some set parameters I have in the code, this is for deciding the chains, noise, bits and such. Then I create the CRPs for the specific PUF. Next if input mapping is turned on the CRPs are preprocessed to the PUF's architecture. For example, for the Arbiter and XOR PUF, the raw challenge bits are looped through, and for each position in the challenge set the feature is calculated by multiplying all the subsequent bit positions. The end result is the same length bit set, but with the parity features calculated for each position, indicating the effect of the delay on the final response. Next, the attack is trained on the challenges and responses for a certain number of epochs and the graph is saved. Then the accuracy testing function is run on a new set of challenges the model has not trained on, again the results are saved. From here, there are a few folders in the directory that correspond to the attack and the number, so you can easily check the training results. This same process is held for each attack, and they all have their own folders for graphs, training parameters, results, and saved models. To create the attacks, I used a Python library, sklearn, and the framework they have to train linear regression. For the perceptron attack, I create a single-layer network with sigmoid activation, and use SGD (Stochastic Gradient Descent) optimizer and BCE (Binary Cross Entropy) loss. This was effective since the responses were just 1 or 0 for the challenge bits. Finally, the neural network was similar, but I had four fully connected layers with dropout to try and increase the patterns the model would learn and prevent overfitting."
date: 2025-04-01
thumbnail: https://aryashetty08.github.io/assets/img/thumb.png
github: https://youtube.com
video: https://google.com
pdf: https://aryashetty08.github.io/assets/img/thumb.png
images:
  - https://aryashetty08.github.io/assets/img/thumb.png
  - https://aryashetty08.github.io/assets/img/thumb.png
---
